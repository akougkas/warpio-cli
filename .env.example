# =================================================================
# WARPIO CLI - Environment Configuration Example
# =================================================================
# Copy this file to .env and update the values according to your setup

# -----------------------------------------------------------------
# AI PROVIDER API KEYS
# -----------------------------------------------------------------

# Gemini API Key (Required for Gemini models)
# Get your key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# OpenAI API Key (Optional - for future integration)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (Optional - for future integration)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# -----------------------------------------------------------------
# LOCAL MODEL PROVIDERS
# -----------------------------------------------------------------

# Ollama Server Configuration
# Default: http://localhost:11434
OLLAMA_HOST=http://localhost:11434

# LM Studio Server Configuration  
# Default: http://localhost:1234
LMSTUDIO_HOST=http://192.168.86.20:1234
LMSTUDIO_API_KEY=lm-studio

# -----------------------------------------------------------------
# DEVELOPMENT SETTINGS
# -----------------------------------------------------------------

# Enable debug mode for local development
DEBUG=false

# Telemetry settings (local or gcp)
TELEMETRY_TARGET=local

# Google Cloud Project (for Vertex AI)
GOOGLE_CLOUD_PROJECT=your-project-id
GOOGLE_CLOUD_LOCATION=us-central1

# -----------------------------------------------------------------
# ADVANCED CONFIGURATION
# -----------------------------------------------------------------

# Proxy configuration (if needed)
# PROXY=http://user:password@proxy.company.com:8080

# Sandbox configuration
# GEMINI_SANDBOX=true

# Custom model endpoints
# CUSTOM_MODEL_ENDPOINT=https://api.example.com/v1